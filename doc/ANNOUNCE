$Header: /data/zender/nco_20150216/nco/doc/ANNOUNCE,v 1.475 2012-05-19 00:47:04 zender Exp $ -*-text-*-

The netCDF operators NCO version 4.2.0 are ready. 

http://nco.sf.net (Homepage)
http://dust.ess.uci.edu/nco (Homepage "mirror")

The minor release change in numbering of this release, from 4.1.0 to
4.2.0, was made to mark the change in NCO status to funded (by NASA)
status. It also helps to alleviate some confusion between netCDF and
NCO version numbering. netCDF 4.2.x just came out and it seems less 
confusing to call the NCO developed with it NCO 4.2.x rather than NCO
4.1.x. 

NASA has started funding NCO to develop support for netCDF4 groups
and to write NCO wrappers for HDF-EOS files. A job ad has been posted
for a programmer position associated with this project:

http://dust.ess.uci.edu/hire/prg_anl_05_adv.pdf
http://ess.uci.edu/opportunity/zender20120327

Work on NCO 4.2.1 is underway, focused on making a more robust
build/configuration environment, addressing the MM3 issue in other
(non-ncks) operators, and on simplifying issues described in the 
KNOWN BUGS NOT YET FIXED section below.

Enjoy,
Charlie

Other "New stuff" in 4.2.0 summary (full details always in ChangeLog):

A. Workaround slow copies of record variables.
   Normally encountered on Multi-record Multi-variable netCDF3 files
   (MM3s), this is also known as the MM3-workaround. 
   The first MM3 workaround went into ncks in NCO 4.1.0.
   The latest NCO also includes MM3 speedups in fxm
   http://nco.sf.net#bug_mm3

A. NaN means Not a Number in IEEE-speak
   Recently I learned that some people use NaN for a missing value,
   and that netCDF supports NaNs. So NCO should, too, but does not.
   Currently the workaround is to change the missing value to non-NaN,
   then perform arithmetic, then change the missing value back to Nan.
   However, show of hands: How many people would like NCO to handle
   missing values that are NaN without using a workaround? i.e., for 
   NCO to do all the checking itself?
   ncwa now correctly handles averages of missing values that are NaN.
   Should we spend time supporting NaN for all arithmetic functions?

A. ncks now prints variables of type NC_INT with %i instead of %li
   formatting. This fixes TODO nco1040.

A. ncra used to initialize counting arrays to one incorrectly.
   This could cause a bug with the ncra -y ttl (i.e., total) function.
   This fixes TODO nco1039. Thanks to Ken5746 for reporting this. 

A. All operators allow specification of buffer size for reading and
   writing files. Specify size with --bfr_sz_hnt or --buffer_size_hint: 
   # Request 2 MB file buffer instead of default 8 kB buffer
   ncks -O -D 3 --bfr_sz=2097152 ~/nco/data/in.nc ~/foo.nc
   Larger sizes can increase access speed by reducing the number of 
   system calls netCDF makes to read/write data from/to disk.
   http://nco.sf.net/nco.html#bfr
   Thanks to Andy Mai for reporting Rob Latham's suggestion for this.

A. ncecat no longer glues a record dimension to any auxiliary coordinate
   variables (latixy, longxy, ...) or bounds (lat_bnds, lon_bnds, ...). 
   These are variables specified in the "coordinates" or "bounds" 
   attribute, respectively.
   Note that regular (1D) coordinate variables (lat, lon, time)
   may also be listed as auxiliary coordinate variables.
   But ncecat never added a record dimension to "normal" 1D coordinates.
   Thanks to Patrick Brockmann for this suggestion. 

A. ncap2 append mode (i.e., ncap2 -A) now works when variables to be 
   appended contain dimensions that already exist in the output file.
   (The rest of NCO has always done this correctly, but ncap2 is 
   architected quite differently).
   Thanks to user mullers for reminding us about this bug, and to
   Henry Butowsky for fixing it. fxm

KNOWN BUGS NOT YET FIXED:

   This section of the ANNOUNCE file is intended to make clear the
   existence and severity of known, not yet fixed, problems. 

A. NOT YET FIXED
   Correctly read netCDF4 input over DAP, write netCDF4 output, then read resulting file.
   Replacing netCDF4 with netCDF3 in either location of preceding sentence leads to success.
   DAP non-transparency: Works locally, fails through DAP server.

   Demonstration:
   ncks -4 -O -v three_dmn_rec_var http://motherlode.ucar.edu:8080/thredds/dodsC/testdods/in_4.nc ~/foo.nc
   ncks ~/foo.nc # breaks with "NetCDF: Invalid dimension ID or name"

   20120329: Verified problem still exists
   Bug report filed: netCDF #QUN-641037: dimension ID ordering assumptions

B. NOT YET FIXED
   netCDF4 library fails when renaming dimension and variable using
   that dimension, in either order. Works fine with netCDF3.
   Problem with netCDF4 library implementation.

   Demonstration:
   ncks -O -4 -v lat_T42 ~/nco/data/in.nc ~/foo.nc
   ncrename -O -D 2 -d lat_T42,lat -v lat_T42,lat ~/foo.nc ~/foo2.nc # Breaks with "NetCDF: HDF error"
   ncks -m ~/foo.nc

   20120329: Verified problem still exists
   Bug report filed: netCDF #YQN-334036: problem renaming dimension and coordinate in netCDF4 file

C. NOT YET FIXED
   Unable to retrieve contents of variables with period '.' in name
   Metadata is returned successfully, data is not.
   DAP non-transparency: Works locally, fails through DAP server.

   Demonstration:
   ncks -O -C -D 3 -v var_nm.dot -p http://motherlode.ucar.edu:8080/thredds/dodsC/testdods in.nc # Fails to find variable

   20120329: Verified problem still exists. Stopped testing because
   inclusion of var_nm.dot broke all test scripts.
   Bug report filed: https://www.unidata.ucar.edu/jira/browse/NCF-47

"Sticky" reminders:

A. All operators support netCDF4 chunking options:
   These options can improve performance on large datasets.
   Large file users: Send us suggestions on useful chunking patterns!
   ncks -O -4 --cnk_plc=all in.nc out.nc
   http://nco.sf.net/nco.html#chunking

B. Pre-built, up-to-date Debian Sid & Ubuntu Maverick packages:
   http://nco.sf.net#debian

C. Pre-built Fedora and CentOS RPMs:
   http://nco.sf.net#rpm

D. Did you try SWAMP (Script Workflow Analysis for MultiProcessing)?
   SWAMP efficiently schedules/executes NCO scripts on remote servers:  

   http://swamp.googlecode.com

   SWAMP can work command-line operator analysis scripts besides NCO. 
   If you must transfer lots of data from a server to your client
   before you analyze it, then SWAMP will likely speed things up. 

E. NCO support for netCDF4 features is tracked at

   http://nco.sf.net/nco.html#nco4

   NCO supports netCDF4 atomic data types, compression, and chunking.
   NCO 4.2.0 with was built and tested with HDF5 hdf5-1.8.7 and with
   4.2-snapshot2012020522.
   NCO may not build with earlier, and should build with later, netCDF4 releases.
   This is particularly true since NCO 4.2.0 takes advantage of an
   internal change to the netCDF nc_def_var_chunking() API in June 2009. 

   export NETCDF4_ROOT=/usr/local/netcdf4 # Set netCDF4 location
   cd ~/nco;./configure --enable-netcdf4  # Configure mechanism -or-
   cd ~/nco/bld;make dir;make all;make ncap2 # Old Makefile mechanism

F. Have you seen the NCO logo candidates by Tony Freeman, Rich
   Signell, Rob Hetland, and Andrea Cimatoribus? 
   http://nco.sf.net
   Tell us what you think...

